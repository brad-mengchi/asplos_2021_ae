//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26218862
// Cuda compilation tools, release 10.1, V10.1.168
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_70
.address_size 64

.func  (.param .b32 func_retval0) _ZN5Plain12intersectionE5Rayon
(
	.param .b64 _ZN5Plain12intersectionE5Rayon_param_0,
	.param .align 4 .b8 _ZN5Plain12intersectionE5Rayon_param_1[24]
)
;
.func  (.param .align 4 .b8 func_retval0[12]) _ZN5Plain10getNormaleE6float3
(
	.param .b64 _ZN5Plain10getNormaleE6float3_param_0,
	.param .align 4 .b8 _ZN5Plain10getNormaleE6float3_param_1[12]
)
;
.func  (.param .b32 func_retval0) _ZN6Sphere12intersectionE5Rayon
(
	.param .b64 _ZN6Sphere12intersectionE5Rayon_param_0,
	.param .align 4 .b8 _ZN6Sphere12intersectionE5Rayon_param_1[24]
)
;
.func  (.param .align 4 .b8 func_retval0[12]) _ZN6Sphere10getNormaleE6float3
(
	.param .b64 _ZN6Sphere10getNormaleE6float3_param_0,
	.param .align 4 .b8 _ZN6Sphere10getNormaleE6float3_param_1[12]
)
;
.global .attribute(.managed) .align 16 .b8 buf5[128];
.const .align 16 .b8 MView[48];
.global .align 8 .u64 _ZTV5Plain[4] = {0, 0, _ZN5Plain12intersectionE5Rayon, _ZN5Plain10getNormaleE6float3};
.global .align 8 .u64 _ZTV6Sphere[4] = {0, 0, _ZN6Sphere12intersectionE5Rayon, _ZN6Sphere10getNormaleE6float3};
.global .attribute(.managed) .align 8 .u64 vfun_table;
.global .attribute(.managed) .align 4 .u32 tree_size_g;
.global .attribute(.managed) .align 8 .u64 temp_copyBack;
.global .attribute(.managed) .align 8 .u64 temp_TP;
.global .attribute(.managed) .align 8 .u64 temp_coal;

.func  (.param .b32 func_retval0) _ZN5Plain12intersectionE5Rayon(
	.param .b64 _ZN5Plain12intersectionE5Rayon_param_0,
	.param .align 4 .b8 _ZN5Plain12intersectionE5Rayon_param_1[24]
)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [_ZN5Plain12intersectionE5Rayon_param_0];
	ld.param.f32 	%f8, [_ZN5Plain12intersectionE5Rayon_param_1+8];
	ld.param.f32 	%f7, [_ZN5Plain12intersectionE5Rayon_param_1+4];
	ld.param.f32 	%f6, [_ZN5Plain12intersectionE5Rayon_param_1];
	ld.param.f32 	%f11, [_ZN5Plain12intersectionE5Rayon_param_1+20];
	ld.param.f32 	%f10, [_ZN5Plain12intersectionE5Rayon_param_1+16];
	ld.param.f32 	%f9, [_ZN5Plain12intersectionE5Rayon_param_1+12];
	mov.f32 	%f13, 0f3F800000;
	rsqrt.approx.f32 	%f1, %f13;
	mul.f32 	%f2, %f1, 0f00000000;
	mul.f32 	%f14, %f9, %f2;
	fma.rn.f32 	%f15, %f10, %f1, %f14;
	fma.rn.f32 	%f3, %f11, %f2, %f15;
	abs.f32 	%f16, %f3;
	setp.lt.f32	%p1, %f16, 0f38D1B717;
	mov.f32 	%f30, 0f00000000;
	@%p1 bra 	BB0_2;

	ld.v2.f32 	{%f17, %f18}, [%rd1+24];
	sub.f32 	%f21, %f6, %f17;
	sub.f32 	%f22, %f7, %f18;
	ld.f32 	%f23, [%rd1+32];
	sub.f32 	%f24, %f8, %f23;
	mul.f32 	%f25, %f1, %f22;
	fma.rn.f32 	%f26, %f2, %f21, %f25;
	fma.rn.f32 	%f27, %f2, %f24, %f26;
	neg.f32 	%f28, %f27;
	div.rn.f32 	%f29, %f28, %f3;
	setp.gt.f32	%p2, %f29, 0f00000000;
	selp.f32	%f30, %f29, 0f00000000, %p2;

BB0_2:
	st.param.f32	[func_retval0+0], %f30;
	ret;
}

.func  (.param .align 4 .b8 func_retval0[12]) _ZN5Plain10getNormaleE6float3(
	.param .b64 _ZN5Plain10getNormaleE6float3_param_0,
	.param .align 4 .b8 _ZN5Plain10getNormaleE6float3_param_1[12]
)
{
	.reg .f32 	%f<4>;


	mov.f32 	%f1, 0f3F800000;
	rsqrt.approx.f32 	%f2, %f1;
	mul.f32 	%f3, %f2, 0f00000000;
	st.param.f32	[func_retval0+0], %f3;
	st.param.f32	[func_retval0+4], %f2;
	st.param.f32	[func_retval0+8], %f3;
	ret;
}

.func  (.param .b32 func_retval0) _ZN6Sphere12intersectionE5Rayon(
	.param .b64 _ZN6Sphere12intersectionE5Rayon_param_0,
	.param .align 4 .b8 _ZN6Sphere12intersectionE5Rayon_param_1[24]
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<36>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [_ZN6Sphere12intersectionE5Rayon_param_0];
	ld.param.f32 	%f8, [_ZN6Sphere12intersectionE5Rayon_param_1+20];
	ld.param.f32 	%f9, [_ZN6Sphere12intersectionE5Rayon_param_1+12];
	ld.param.f32 	%f10, [_ZN6Sphere12intersectionE5Rayon_param_1+16];
	ld.param.f32 	%f11, [_ZN6Sphere12intersectionE5Rayon_param_1+8];
	ld.param.f32 	%f12, [_ZN6Sphere12intersectionE5Rayon_param_1+4];
	ld.param.f32 	%f13, [_ZN6Sphere12intersectionE5Rayon_param_1];
	ld.v2.f32 	{%f14, %f15}, [%rd1+24];
	ld.v2.f32 	{%f18, %f19}, [%rd1+32];
	sub.f32 	%f22, %f14, %f13;
	sub.f32 	%f23, %f15, %f12;
	sub.f32 	%f24, %f18, %f11;
	mul.f32 	%f25, %f10, %f23;
	fma.rn.f32 	%f26, %f9, %f22, %f25;
	fma.rn.f32 	%f1, %f8, %f24, %f26;
	mul.f32 	%f27, %f23, %f23;
	fma.rn.f32 	%f28, %f22, %f22, %f27;
	fma.rn.f32 	%f2, %f24, %f24, %f28;
	mul.f32 	%f3, %f19, %f19;
	setp.lt.f32	%p1, %f1, 0f00000000;
	setp.gt.f32	%p2, %f2, %f3;
	and.pred  	%p3, %p1, %p2;
	mov.f32 	%f35, 0f00000000;
	@%p3 bra 	BB2_3;

	mul.f32 	%f30, %f1, %f1;
	sub.f32 	%f4, %f2, %f30;
	setp.gt.f32	%p4, %f4, %f3;
	@%p4 bra 	BB2_3;

	sub.f32 	%f31, %f3, %f4;
	sqrt.rn.f32 	%f32, %f31;
	neg.f32 	%f33, %f32;
	selp.f32	%f34, %f33, %f32, %p2;
	add.f32 	%f35, %f1, %f34;

BB2_3:
	st.param.f32	[func_retval0+0], %f35;
	ret;
}

.func  (.param .align 4 .b8 func_retval0[12]) _ZN6Sphere10getNormaleE6float3(
	.param .b64 _ZN6Sphere10getNormaleE6float3_param_0,
	.param .align 4 .b8 _ZN6Sphere10getNormaleE6float3_param_1[12]
)
{
	.reg .f32 	%f<19>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [_ZN6Sphere10getNormaleE6float3_param_0];
	ld.param.f32 	%f1, [_ZN6Sphere10getNormaleE6float3_param_1+8];
	ld.param.f32 	%f2, [_ZN6Sphere10getNormaleE6float3_param_1+4];
	ld.param.f32 	%f3, [_ZN6Sphere10getNormaleE6float3_param_1];
	ld.v2.f32 	{%f4, %f5}, [%rd1+24];
	ld.f32 	%f8, [%rd1+32];
	sub.f32 	%f9, %f3, %f4;
	sub.f32 	%f10, %f2, %f5;
	sub.f32 	%f11, %f1, %f8;
	mul.f32 	%f12, %f10, %f10;
	fma.rn.f32 	%f13, %f9, %f9, %f12;
	fma.rn.f32 	%f14, %f11, %f11, %f13;
	rsqrt.approx.f32 	%f15, %f14;
	mul.f32 	%f16, %f15, %f9;
	mul.f32 	%f17, %f15, %f10;
	mul.f32 	%f18, %f15, %f11;
	st.param.f32	[func_retval0+0], %f16;
	st.param.f32	[func_retval0+4], %f17;
	st.param.f32	[func_retval0+8], %f18;
	ret;
}

	// .globl	_Z9vptrPatchPvS_ji
.visible .entry _Z9vptrPatchPvS_ji(
	.param .u64 _Z9vptrPatchPvS_ji_param_0,
	.param .u64 _Z9vptrPatchPvS_ji_param_1,
	.param .u32 _Z9vptrPatchPvS_ji_param_2,
	.param .u32 _Z9vptrPatchPvS_ji_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd1, [_Z9vptrPatchPvS_ji_param_0];
	ld.param.u64 	%rd2, [_Z9vptrPatchPvS_ji_param_1];
	ld.param.u32 	%r2, [_Z9vptrPatchPvS_ji_param_2];
	ld.param.u32 	%r3, [_Z9vptrPatchPvS_ji_param_3];
	mov.u32 	%r4, %tid.x;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r4;
	setp.ge.s32	%p1, %r1, %r3;
	@%p1 bra 	BB4_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.lo.s32 	%r7, %r1, %r2;
	cvt.u64.u32	%rd4, %r7;
	add.s64 	%rd5, %rd3, %rd4;
	cvta.to.global.u64 	%rd6, %rd2;
	ld.global.u8 	%rs1, [%rd6];
	st.global.u8 	[%rd5], %rs1;
	ld.global.u8 	%rs2, [%rd6+1];
	st.global.u8 	[%rd5+1], %rs2;
	ld.global.u8 	%rs3, [%rd6+2];
	st.global.u8 	[%rd5+2], %rs3;
	ld.global.u8 	%rs4, [%rd6+3];
	st.global.u8 	[%rd5+3], %rs4;
	ld.global.u8 	%rs5, [%rd6+4];
	st.global.u8 	[%rd5+4], %rs5;
	ld.global.u8 	%rs6, [%rd6+5];
	st.global.u8 	[%rd5+5], %rs6;
	ld.global.u8 	%rs7, [%rd6+6];
	st.global.u8 	[%rd5+6], %rs7;
	ld.global.u8 	%rs8, [%rd6+7];
	st.global.u8 	[%rd5+7], %rs8;

BB4_2:
	ret;
}

	// .globl	_Z15initObject_kernPP6ObjectPfi
.visible .entry _Z15initObject_kernPP6ObjectPfi(
	.param .u64 _Z15initObject_kernPP6ObjectPfi_param_0,
	.param .u64 _Z15initObject_kernPP6ObjectPfi_param_1,
	.param .u32 _Z15initObject_kernPP6ObjectPfi_param_2
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<19>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd3, [_Z15initObject_kernPP6ObjectPfi_param_0];
	ld.param.u64 	%rd4, [_Z15initObject_kernPP6ObjectPfi_param_1];
	ld.param.u32 	%r2, [_Z15initObject_kernPP6ObjectPfi_param_2];
	cvta.to.global.u64 	%rd1, %rd4;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB5_6;

	cvta.to.global.u64 	%rd5, %rd3;
	mul.wide.s32 	%rd6, %r1, 8;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u64 	%rd8, [%rd7];
	and.b64  	%rd2, %rd8, 281474976710655;
	setp.eq.s32	%p2, %r1, 0;
	@%p2 bra 	BB5_4;

	setp.eq.s64	%p3, %rd2, 0;
	@%p3 bra 	BB5_6;

	shl.b32 	%r6, %r1, 3;
	mul.wide.s32 	%rd9, %r6, 4;
	add.s64 	%rd10, %rd1, %rd9;
	mov.f32 	%f1, 0f00000000;
	ld.global.f32 	%f2, [%rd10+4];
	ld.global.f32 	%f3, [%rd10];
	ld.global.f32 	%f4, [%rd10+12];
	ld.global.f32 	%f5, [%rd10+8];
	ld.global.f32 	%f6, [%rd10+20];
	ld.global.f32 	%f7, [%rd10+16];
	ld.global.f32 	%f8, [%rd10+28];
	ld.global.f32 	%f9, [%rd10+24];
	st.v2.f32 	[%rd2+24], {%f1, %f1};
	mov.u32 	%r7, 0;
	st.u32 	[%rd2+32], %r7;
	mov.u64 	%rd11, _ZTV6Sphere;
	add.s64 	%rd12, %rd11, 16;
	cvta.global.u64 	%rd13, %rd12;
	st.u64 	[%rd2], %rd13;
	st.v2.f32 	[%rd2+8], {%f3, %f2};
	st.v2.f32 	[%rd2+16], {%f5, %f4};
	st.v2.f32 	[%rd2+24], {%f7, %f6};
	st.v2.f32 	[%rd2+32], {%f9, %f8};
	bra.uni 	BB5_6;

BB5_4:
	setp.eq.s64	%p4, %rd2, 0;
	@%p4 bra 	BB5_6;

	mov.f32 	%f10, 0f00000000;
	ld.global.f32 	%f11, [%rd1+4];
	ld.global.f32 	%f12, [%rd1];
	ld.global.f32 	%f13, [%rd1+12];
	ld.global.f32 	%f14, [%rd1+8];
	ld.global.f32 	%f15, [%rd1+20];
	ld.global.f32 	%f16, [%rd1+16];
	ld.global.f32 	%f17, [%rd1+28];
	ld.global.f32 	%f18, [%rd1+24];
	st.v2.f32 	[%rd2+24], {%f10, %f10};
	mov.u32 	%r8, 0;
	st.u32 	[%rd2+32], %r8;
	mov.u64 	%rd14, _ZTV5Plain;
	add.s64 	%rd15, %rd14, 16;
	cvta.global.u64 	%rd16, %rd15;
	st.u64 	[%rd2], %rd16;
	st.v2.f32 	[%rd2+8], {%f12, %f11};
	st.v2.f32 	[%rd2+16], {%f14, %f13};
	st.v2.f32 	[%rd2+24], {%f16, %f15};
	st.v2.f32 	[%rd2+32], {%f18, %f17};

BB5_6:
	ret;
}

	// .globl	_Z6renderPjPP6Objectjjfi
.visible .entry _Z6renderPjPP6Objectjjfi(
	.param .u64 _Z6renderPjPP6Objectjjfi_param_0,
	.param .u64 _Z6renderPjPP6Objectjjfi_param_1,
	.param .u32 _Z6renderPjPP6Objectjjfi_param_2,
	.param .u32 _Z6renderPjPP6Objectjjfi_param_3,
	.param .f32 _Z6renderPjPP6Objectjjfi_param_4,
	.param .u32 _Z6renderPjPP6Objectjjfi_param_5
)
{
	.local .align 16 .b8 	__local_depot6[80];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<72>;
	.reg .f32 	%f<497>;
	.reg .b32 	%r<130>;
	.reg .b64 	%rd<89>;


	mov.u64 	%SPL, __local_depot6;
	ld.param.u64 	%rd9, [_Z6renderPjPP6Objectjjfi_param_0];
	ld.param.u64 	%rd10, [_Z6renderPjPP6Objectjjfi_param_1];
	ld.param.u32 	%r42, [_Z6renderPjPP6Objectjjfi_param_2];
	ld.param.u32 	%r43, [_Z6renderPjPP6Objectjjfi_param_3];
	ld.param.f32 	%f118, [_Z6renderPjPP6Objectjjfi_param_4];
	ld.param.u32 	%r44, [_Z6renderPjPP6Objectjjfi_param_5];
	cvta.to.global.u64 	%rd1, %rd10;
	add.u64 	%rd2, %SPL, 0;
	mov.f32 	%f119, 0f3F800000;
	mov.f32 	%f120, 0f00000000;
	st.local.v4.f32 	[%rd2], {%f120, %f120, %f120, %f119};
	st.local.v4.f32 	[%rd2+16], {%f120, %f120, %f120, %f119};
	st.local.v4.f32 	[%rd2+32], {%f120, %f120, %f120, %f119};
	st.local.v4.f32 	[%rd2+48], {%f120, %f120, %f120, %f119};
	st.local.v4.f32 	[%rd2+64], {%f120, %f120, %f120, %f119};
	mov.u32 	%r45, %ntid.x;
	mov.u32 	%r46, %ctaid.x;
	mul24.lo.u32 	%r47, %r46, %r45;
	mov.u32 	%r48, %tid.x;
	add.s32 	%r1, %r48, %r47;
	mov.u32 	%r49, %ntid.y;
	mov.u32 	%r50, %ctaid.y;
	mul24.lo.u32 	%r51, %r50, %r49;
	mov.u32 	%r52, %tid.y;
	add.s32 	%r2, %r52, %r51;
	setp.ge.u32	%p5, %r1, %r42;
	setp.ge.u32	%p6, %r2, %r43;
	or.pred  	%p7, %p5, %p6;
	@%p7 bra 	BB6_50;

	cvta.to.global.u64 	%rd12, %rd9;
	mad.lo.s32 	%r53, %r2, %r42, %r1;
	mul.wide.u32 	%rd13, %r53, 4;
	add.s64 	%rd3, %rd12, %rd13;
	mov.u32 	%r108, 0;
	st.global.u32 	[%rd3], %r108;
	min.u32 	%r55, %r42, %r43;
	cvt.rn.f32.u32	%f121, %r55;
	mov.f32 	%f122, 0f40000000;
	div.rn.f32 	%f123, %f122, %f121;
	ld.const.v4.f32 	{%f124, %f125, %f126, %f473}, [MView];
	ld.const.v4.f32 	{%f131, %f132, %f133, %f472}, [MView+16];
	ld.const.v4.f32 	{%f138, %f139, %f140, %f471}, [MView+32];
	cvt.rn.f32.u32	%f145, %r42;
	mul.f32 	%f146, %f145, 0f3F000000;
	cvt.rn.f32.u32	%f147, %r1;
	sub.f32 	%f148, %f147, %f146;
	mul.f32 	%f149, %f148, %f138;
	mul.f32 	%f150, %f148, %f139;
	mul.f32 	%f151, %f148, %f140;
	mul.f32 	%f152, %f123, %f149;
	mul.f32 	%f153, %f123, %f150;
	mul.f32 	%f154, %f123, %f151;
	fma.rn.f32 	%f155, %f124, %f118, %f152;
	fma.rn.f32 	%f156, %f125, %f118, %f153;
	fma.rn.f32 	%f157, %f126, %f118, %f154;
	cvt.rn.f32.u32	%f158, %r43;
	mul.f32 	%f159, %f158, 0f3F000000;
	cvt.rn.f32.u32	%f160, %r2;
	sub.f32 	%f161, %f160, %f159;
	mul.f32 	%f162, %f161, %f131;
	mul.f32 	%f163, %f161, %f132;
	mul.f32 	%f164, %f161, %f133;
	fma.rn.f32 	%f165, %f123, %f162, %f155;
	fma.rn.f32 	%f166, %f123, %f163, %f156;
	fma.rn.f32 	%f167, %f123, %f164, %f157;
	mul.f32 	%f168, %f166, %f166;
	fma.rn.f32 	%f169, %f165, %f165, %f168;
	fma.rn.f32 	%f170, %f167, %f167, %f169;
	rsqrt.approx.f32 	%f171, %f170;
	mul.f32 	%f470, %f171, %f165;
	mul.f32 	%f469, %f171, %f166;
	mul.f32 	%f468, %f171, %f167;
	bar.sync 	0;
	and.b32  	%r3, %r44, 3;

BB6_2:
	mov.f32 	%f479, 0f461C4000;
	setp.lt.s32	%p8, %r44, 1;
	@%p8 bra 	BB6_13;

	mov.f32 	%f474, 0f461C4000;
	mov.u32 	%r110, 0;
	setp.eq.s32	%p9, %r3, 0;
	@%p9 bra 	BB6_4;

	setp.eq.s32	%p10, %r3, 1;
	@%p10 bra 	BB6_9;

	setp.eq.s32	%p11, %r3, 2;
	@%p11 bra 	BB6_8;

	ld.global.nc.u64 	%rd14, [%rd1];
	and.b64  	%rd15, %rd14, 281474976710655;
	ld.u64 	%rd16, [%rd15];
	ld.u64 	%rd17, [%rd16];
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd15;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f473;
	st.param.f32	[param1+4], %f472;
	st.param.f32	[param1+8], %f471;
	st.param.f32	[param1+12], %f470;
	st.param.f32	[param1+16], %f469;
	st.param.f32	[param1+20], %f468;
	.param .b32 retval0;
	prototype_0 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd17, 
	(
	param0, 
	param1
	)
	, prototype_0;
	ld.param.f32	%f177, [retval0+0];
	
	//{
	}// Callseq End 0
	setp.gt.f32	%p12, %f177, 0f00000000;
	setp.lt.f32	%p13, %f177, 0f461C4000;
	and.pred  	%p14, %p12, %p13;
	selp.b32	%r119, 0, %r119, %p14;
	selp.f32	%f474, %f177, 0f461C4000, %p14;
	mov.u32 	%r110, 1;

BB6_8:
	mul.wide.u32 	%rd18, %r110, 8;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.nc.u64 	%rd20, [%rd19];
	and.b64  	%rd21, %rd20, 281474976710655;
	ld.u64 	%rd22, [%rd21];
	ld.u64 	%rd23, [%rd22];
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd21;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f473;
	st.param.f32	[param1+4], %f472;
	st.param.f32	[param1+8], %f471;
	st.param.f32	[param1+12], %f470;
	st.param.f32	[param1+16], %f469;
	st.param.f32	[param1+20], %f468;
	.param .b32 retval0;
	prototype_1 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd23, 
	(
	param0, 
	param1
	)
	, prototype_1;
	ld.param.f32	%f178, [retval0+0];
	
	//{
	}// Callseq End 1
	setp.gt.f32	%p15, %f178, 0f00000000;
	setp.lt.f32	%p16, %f178, %f474;
	and.pred  	%p17, %p15, %p16;
	selp.b32	%r119, %r110, %r119, %p17;
	selp.f32	%f474, %f178, %f474, %p17;
	add.s32 	%r110, %r110, 1;

BB6_9:
	mul.wide.s32 	%rd24, %r110, 8;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.nc.u64 	%rd26, [%rd25];
	and.b64  	%rd27, %rd26, 281474976710655;
	ld.u64 	%rd28, [%rd27];
	ld.u64 	%rd29, [%rd28];
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd27;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f473;
	st.param.f32	[param1+4], %f472;
	st.param.f32	[param1+8], %f471;
	st.param.f32	[param1+12], %f470;
	st.param.f32	[param1+16], %f469;
	st.param.f32	[param1+20], %f468;
	.param .b32 retval0;
	prototype_2 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd29, 
	(
	param0, 
	param1
	)
	, prototype_2;
	ld.param.f32	%f179, [retval0+0];
	
	//{
	}// Callseq End 2
	setp.gt.f32	%p18, %f179, 0f00000000;
	setp.lt.f32	%p19, %f179, %f474;
	and.pred  	%p20, %p18, %p19;
	selp.b32	%r115, %r110, %r119, %p20;
	selp.f32	%f474, %f179, %f474, %p20;
	add.s32 	%r110, %r110, 1;
	mov.f32 	%f479, %f474;
	mov.u32 	%r119, %r115;
	bra.uni 	BB6_10;

BB6_4:
	mov.u32 	%r115, %r119;
	mov.f32 	%f479, %f120;
	mov.u32 	%r119, %r110;

BB6_10:
	setp.lt.u32	%p21, %r44, 4;
	@%p21 bra 	BB6_13;

	mul.wide.s32 	%rd30, %r110, 8;
	add.s64 	%rd88, %rd1, %rd30;
	mov.f32 	%f479, %f474;
	mov.u32 	%r119, %r115;

BB6_12:
	ld.global.nc.u64 	%rd31, [%rd88];
	and.b64  	%rd32, %rd31, 281474976710655;
	ld.u64 	%rd33, [%rd32];
	ld.u64 	%rd34, [%rd33];
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd32;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f473;
	st.param.f32	[param1+4], %f472;
	st.param.f32	[param1+8], %f471;
	st.param.f32	[param1+12], %f470;
	st.param.f32	[param1+16], %f469;
	st.param.f32	[param1+20], %f468;
	.param .b32 retval0;
	prototype_3 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd34, 
	(
	param0, 
	param1
	)
	, prototype_3;
	ld.param.f32	%f180, [retval0+0];
	
	//{
	}// Callseq End 3
	setp.gt.f32	%p22, %f180, 0f00000000;
	setp.lt.f32	%p23, %f180, %f479;
	and.pred  	%p24, %p22, %p23;
	selp.b32	%r63, %r110, %r119, %p24;
	selp.f32	%f181, %f180, %f479, %p24;
	ld.global.nc.u64 	%rd35, [%rd88+8];
	and.b64  	%rd36, %rd35, 281474976710655;
	ld.u64 	%rd37, [%rd36];
	ld.u64 	%rd38, [%rd37];
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd36;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f473;
	st.param.f32	[param1+4], %f472;
	st.param.f32	[param1+8], %f471;
	st.param.f32	[param1+12], %f470;
	st.param.f32	[param1+16], %f469;
	st.param.f32	[param1+20], %f468;
	.param .b32 retval0;
	prototype_4 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd38, 
	(
	param0, 
	param1
	)
	, prototype_4;
	ld.param.f32	%f182, [retval0+0];
	
	//{
	}// Callseq End 4
	setp.gt.f32	%p25, %f182, 0f00000000;
	setp.lt.f32	%p26, %f182, %f181;
	and.pred  	%p27, %p25, %p26;
	add.s32 	%r64, %r110, 1;
	selp.b32	%r65, %r64, %r63, %p27;
	selp.f32	%f183, %f182, %f181, %p27;
	ld.global.nc.u64 	%rd39, [%rd88+16];
	and.b64  	%rd40, %rd39, 281474976710655;
	ld.u64 	%rd41, [%rd40];
	ld.u64 	%rd42, [%rd41];
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd40;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f473;
	st.param.f32	[param1+4], %f472;
	st.param.f32	[param1+8], %f471;
	st.param.f32	[param1+12], %f470;
	st.param.f32	[param1+16], %f469;
	st.param.f32	[param1+20], %f468;
	.param .b32 retval0;
	prototype_5 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd42, 
	(
	param0, 
	param1
	)
	, prototype_5;
	ld.param.f32	%f184, [retval0+0];
	
	//{
	}// Callseq End 5
	setp.gt.f32	%p28, %f184, 0f00000000;
	setp.lt.f32	%p29, %f184, %f183;
	and.pred  	%p30, %p28, %p29;
	add.s32 	%r66, %r110, 2;
	selp.b32	%r67, %r66, %r65, %p30;
	selp.f32	%f185, %f184, %f183, %p30;
	ld.global.nc.u64 	%rd43, [%rd88+24];
	and.b64  	%rd44, %rd43, 281474976710655;
	ld.u64 	%rd45, [%rd44];
	ld.u64 	%rd46, [%rd45];
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd44;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f473;
	st.param.f32	[param1+4], %f472;
	st.param.f32	[param1+8], %f471;
	st.param.f32	[param1+12], %f470;
	st.param.f32	[param1+16], %f469;
	st.param.f32	[param1+20], %f468;
	.param .b32 retval0;
	prototype_6 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd46, 
	(
	param0, 
	param1
	)
	, prototype_6;
	ld.param.f32	%f186, [retval0+0];
	
	//{
	}// Callseq End 6
	setp.gt.f32	%p31, %f186, 0f00000000;
	setp.lt.f32	%p32, %f186, %f185;
	and.pred  	%p33, %p31, %p32;
	add.s32 	%r68, %r110, 3;
	selp.b32	%r119, %r68, %r67, %p33;
	selp.f32	%f479, %f186, %f185, %p33;
	add.s64 	%rd88, %rd88, 32;
	add.s32 	%r110, %r110, 4;
	setp.lt.s32	%p34, %r110, %r44;
	@%p34 bra 	BB6_12;

BB6_13:
	setp.geu.f32	%p35, %f479, 0f461C4000;
	setp.leu.f32	%p36, %f479, 0f00000000;
	or.pred  	%p37, %p36, %p35;
	@%p37 bra 	BB6_14;

	mul.wide.u32 	%rd47, %r119, 8;
	add.s64 	%rd48, %rd1, %rd47;
	ld.global.nc.u64 	%rd49, [%rd48];
	and.b64  	%rd50, %rd49, 281474976710655;
	ld.v2.f32 	{%f187, %f188}, [%rd50+8];
	ld.v2.f32 	{%f189, %f190}, [%rd50+16];
	fma.rn.f32 	%f33, %f470, %f479, %f473;
	fma.rn.f32 	%f34, %f469, %f479, %f472;
	fma.rn.f32 	%f35, %f468, %f479, %f471;
	mov.f32 	%f191, 0f41200000;
	sub.f32 	%f192, %f191, %f33;
	sub.f32 	%f193, %f191, %f34;
	sub.f32 	%f194, %f191, %f35;
	mul.f32 	%f195, %f193, %f193;
	fma.rn.f32 	%f196, %f192, %f192, %f195;
	fma.rn.f32 	%f36, %f194, %f194, %f196;
	rsqrt.approx.f32 	%f197, %f36;
	mul.f32 	%f37, %f192, %f197;
	mul.f32 	%f38, %f193, %f197;
	mul.f32 	%f39, %f194, %f197;
	sub.f32 	%f198, %f473, %f33;
	sub.f32 	%f199, %f472, %f34;
	sub.f32 	%f200, %f471, %f35;
	mul.f32 	%f201, %f199, %f199;
	fma.rn.f32 	%f202, %f198, %f198, %f201;
	fma.rn.f32 	%f203, %f200, %f200, %f202;
	rsqrt.approx.f32 	%f204, %f203;
	mul.f32 	%f40, %f198, %f204;
	mul.f32 	%f41, %f199, %f204;
	mul.f32 	%f42, %f200, %f204;
	shr.u64 	%rd51, %rd49, 48;
	ld.global.u64 	%rd52, [vfun_table];
	mul.lo.s64 	%rd53, %rd51, 240;
	add.s64 	%rd54, %rd52, %rd53;
	ld.u64 	%rd55, [%rd54+8];


	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd50;
	.param .align 4 .b8 param1[12];
	st.param.f32	[param1+0], %f33;
	st.param.f32	[param1+4], %f34;
	st.param.f32	[param1+8], %f35;
	.param .align 4 .b8 retval0[12];
	prototype_7 : .callprototype (.param .align 4 .b8 _[12]) _ (.param .b64 _, .param .align 4 .b8 _[12]) ;
	call (retval0), 
%rd55,
	(
	param0, 
	param1
	)
	, prototype_7;
	ld.param.f32	%f43, [retval0+0];
	ld.param.f32	%f44, [retval0+4];
	ld.param.f32	%f45, [retval0+8];
	
	//{
	}// Callseq End 7
	mul.f32 	%f205, %f41, %f44;
	fma.rn.f32 	%f206, %f40, %f43, %f205;
	fma.rn.f32 	%f46, %f42, %f45, %f206;
	setp.lt.f32	%p38, %f46, 0f00000000;
	neg.f32 	%f207, %f43;
	neg.f32 	%f208, %f44;
	neg.f32 	%f209, %f45;
	selp.f32	%f47, %f207, %f43, %p38;
	selp.f32	%f48, %f208, %f44, %p38;
	selp.f32	%f49, %f209, %f45, %p38;
	mul.f32 	%f50, %f187, 0f3D4CCCCD;
	mul.f32 	%f51, %f188, 0f3D4CCCCD;
	mul.f32 	%f52, %f189, 0f3D4CCCCD;
	mul.f32 	%f53, %f190, 0f3D4CCCCD;
	mul.wide.s32 	%rd58, %r108, 16;
	add.s64 	%rd7, %rd2, %rd58;
	st.local.v4.f32 	[%rd7], {%f50, %f51, %f52, %f53};
	mul.f32 	%f210, %f38, %f48;
	fma.rn.f32 	%f211, %f37, %f47, %f210;
	fma.rn.f32 	%f54, %f39, %f49, %f211;
	setp.leu.f32	%p39, %f54, 0f00000000;
	@%p39 bra 	BB6_34;

	fma.rn.f32 	%f55, %f37, 0f38D1B717, %f33;
	fma.rn.f32 	%f56, %f38, 0f38D1B717, %f34;
	fma.rn.f32 	%f57, %f39, 0f38D1B717, %f35;
	@%p8 bra 	BB6_22;

	mov.u32 	%r120, 0;

BB6_18:
	mul.wide.s32 	%rd59, %r120, 8;
	add.s64 	%rd60, %rd1, %rd59;
	ld.global.nc.u64 	%rd61, [%rd60];
	and.b64  	%rd62, %rd61, 281474976710655;
	ld.u64 	%rd63, [%rd62];
	ld.u64 	%rd64, [%rd63];
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd62;
	.param .align 4 .b8 param1[24];
	st.param.f32	[param1+0], %f55;
	st.param.f32	[param1+4], %f56;
	st.param.f32	[param1+8], %f57;
	st.param.f32	[param1+12], %f37;
	st.param.f32	[param1+16], %f38;
	st.param.f32	[param1+20], %f39;
	.param .b32 retval0;
	prototype_8 : .callprototype (.param .b32 _) _ (.param .b64 _, .param .align 4 .b8 _[24]) ;
	call (retval0), 
	%rd64, 
	(
	param0, 
	param1
	)
	, prototype_8;
	ld.param.f32	%f64, [retval0+0];
	
	//{
	}// Callseq End 8
	mov.pred 	%p71, 0;
	setp.leu.f32	%p42, %f64, 0f00000000;
	@%p42 bra 	BB6_20;

	fma.rn.f32 	%f212, %f37, %f64, %f33;
	fma.rn.f32 	%f213, %f38, %f64, %f34;
	fma.rn.f32 	%f214, %f39, %f64, %f35;
	mul.f32 	%f215, %f213, %f213;
	fma.rn.f32 	%f216, %f212, %f212, %f215;
	fma.rn.f32 	%f217, %f214, %f214, %f216;
	setp.gt.f32	%p71, %f217, %f36;

BB6_20:
	add.s32 	%r120, %r120, 1;
	setp.lt.s32	%p43, %r120, %r44;
	setp.eq.f32	%p44, %f64, 0f00000000;
	or.pred  	%p3, %p71, %p44;
	and.pred  	%p45, %p43, %p3;
	@%p45 bra 	BB6_18;

	@!%p3 bra 	BB6_34;
	bra.uni 	BB6_22;

BB6_22:
	mul.wide.s32 	%rd87, %r108, 16;
	add.s64 	%rd86, %rd2, %rd87;
	mov.f32 	%f466, 0f3F800000;
	add.f32 	%f220, %f37, %f40;
	add.f32 	%f221, %f38, %f41;
	mul.f32 	%f222, %f221, %f221;
	fma.rn.f32 	%f223, %f220, %f220, %f222;
	add.f32 	%f224, %f39, %f42;
	fma.rn.f32 	%f225, %f224, %f224, %f223;
	rsqrt.approx.f32 	%f226, %f225;
	mul.f32 	%f227, %f220, %f226;
	mul.f32 	%f228, %f221, %f226;
	mul.f32 	%f229, %f224, %f226;
	min.f32 	%f231, %f466, %f54;
	mul.f32 	%f232, %f187, 0f3E99999A;
	mul.f32 	%f233, %f188, 0f3E99999A;
	mul.f32 	%f234, %f189, 0f3E99999A;
	mul.f32 	%f235, %f190, 0f3E99999A;
	fma.rn.f32 	%f65, %f232, %f231, %f50;
	fma.rn.f32 	%f66, %f233, %f231, %f51;
	fma.rn.f32 	%f67, %f234, %f231, %f52;
	fma.rn.f32 	%f236, %f235, %f231, %f53;
	st.local.v4.f32 	[%rd86], {%f65, %f66, %f67, %f236};
	mul.f32 	%f237, %f48, %f228;
	fma.rn.f32 	%f238, %f47, %f227, %f237;
	fma.rn.f32 	%f239, %f49, %f229, %f238;
	min.f32 	%f240, %f466, %f239;
	max.f32 	%f68, %f120, %f240;
	abs.f32 	%f70, %f68;
	setp.lt.f32	%p46, %f70, 0f00800000;
	mul.f32 	%f245, %f70, 0f4B800000;
	selp.f32	%f246, 0fC3170000, 0fC2FE0000, %p46;
	selp.f32	%f247, %f245, %f70, %p46;
	mov.b32 	 %r70, %f247;
	and.b32  	%r71, %r70, 8388607;
	or.b32  	%r72, %r71, 1065353216;
	mov.b32 	 %f248, %r72;
	shr.u32 	%r73, %r70, 23;
	cvt.rn.f32.u32	%f249, %r73;
	add.f32 	%f250, %f246, %f249;
	setp.gt.f32	%p47, %f248, 0f3FB504F3;
	mul.f32 	%f251, %f248, 0f3F000000;
	add.f32 	%f252, %f250, 0f3F800000;
	selp.f32	%f253, %f251, %f248, %p47;
	selp.f32	%f254, %f252, %f250, %p47;
	add.f32 	%f255, %f253, 0fBF800000;
	add.f32 	%f219, %f253, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f218,%f219;
	// inline asm
	add.f32 	%f256, %f255, %f255;
	mul.f32 	%f257, %f218, %f256;
	mul.f32 	%f258, %f257, %f257;
	mov.f32 	%f259, 0f3C4CAF63;
	mov.f32 	%f260, 0f3B18F0FE;
	fma.rn.f32 	%f261, %f260, %f258, %f259;
	mov.f32 	%f262, 0f3DAAAABD;
	fma.rn.f32 	%f263, %f261, %f258, %f262;
	mul.rn.f32 	%f264, %f263, %f258;
	mul.rn.f32 	%f265, %f264, %f257;
	sub.f32 	%f266, %f255, %f257;
	neg.f32 	%f267, %f257;
	add.f32 	%f268, %f266, %f266;
	fma.rn.f32 	%f269, %f267, %f255, %f268;
	mul.rn.f32 	%f270, %f218, %f269;
	add.f32 	%f271, %f265, %f257;
	sub.f32 	%f272, %f257, %f271;
	add.f32 	%f273, %f265, %f272;
	add.f32 	%f274, %f270, %f273;
	add.f32 	%f275, %f271, %f274;
	sub.f32 	%f276, %f271, %f275;
	add.f32 	%f277, %f274, %f276;
	mov.f32 	%f278, 0f3F317200;
	mul.rn.f32 	%f279, %f254, %f278;
	mov.f32 	%f280, 0f35BFBE8E;
	mul.rn.f32 	%f281, %f254, %f280;
	add.f32 	%f282, %f279, %f275;
	sub.f32 	%f283, %f279, %f282;
	add.f32 	%f284, %f275, %f283;
	add.f32 	%f285, %f277, %f284;
	add.f32 	%f286, %f281, %f285;
	add.f32 	%f287, %f282, %f286;
	sub.f32 	%f288, %f282, %f287;
	add.f32 	%f289, %f286, %f288;
	mov.f32 	%f290, 0f42480000;
	mul.rn.f32 	%f291, %f290, %f287;
	neg.f32 	%f292, %f291;
	fma.rn.f32 	%f293, %f290, %f287, %f292;
	fma.rn.f32 	%f294, %f290, %f289, %f293;
	fma.rn.f32 	%f295, %f120, %f287, %f294;
	add.rn.f32 	%f296, %f291, %f295;
	neg.f32 	%f297, %f296;
	add.rn.f32 	%f298, %f291, %f297;
	add.rn.f32 	%f299, %f298, %f295;
	mov.b32 	 %r74, %f296;
	setp.eq.s32	%p48, %r74, 1118925336;
	add.s32 	%r75, %r74, -1;
	mov.b32 	 %f300, %r75;
	add.f32 	%f301, %f299, 0f37000000;
	selp.f32	%f302, %f300, %f296, %p48;
	selp.f32	%f71, %f301, %f299, %p48;
	mul.f32 	%f303, %f302, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f304, %f303;
	mov.f32 	%f305, 0fBF317200;
	fma.rn.f32 	%f306, %f304, %f305, %f302;
	mov.f32 	%f307, 0fB5BFBE8E;
	fma.rn.f32 	%f308, %f304, %f307, %f306;
	mul.f32 	%f309, %f308, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f310, %f309;
	add.f32 	%f311, %f304, 0f00000000;
	ex2.approx.f32 	%f312, %f311;
	mul.f32 	%f313, %f310, %f312;
	setp.lt.f32	%p49, %f302, 0fC2D20000;
	selp.f32	%f314, 0f00000000, %f313, %p49;
	setp.gt.f32	%p50, %f302, 0f42D20000;
	selp.f32	%f480, 0f7F800000, %f314, %p50;
	setp.eq.f32	%p51, %f480, 0f7F800000;
	@%p51 bra 	BB6_24;

	fma.rn.f32 	%f480, %f480, %f71, %f480;

BB6_24:
	mov.f32 	%f465, 0f41C80000;
	cvt.rzi.f32.f32	%f464, %f465;
	fma.rn.f32 	%f463, %f464, 0fC0000000, 0f42480000;
	abs.f32 	%f462, %f463;
	setp.lt.f32	%p52, %f68, 0f00000000;
	setp.eq.f32	%p53, %f462, 0f3F800000;
	and.pred  	%p4, %p52, %p53;
	mov.b32 	 %r76, %f480;
	xor.b32  	%r77, %r76, -2147483648;
	mov.b32 	 %f315, %r77;
	selp.f32	%f482, %f315, %f480, %p4;
	setp.eq.f32	%p54, %f68, 0f00000000;
	@%p54 bra 	BB6_27;
	bra.uni 	BB6_25;

BB6_27:
	add.f32 	%f318, %f68, %f68;
	selp.f32	%f482, %f318, 0f00000000, %p53;
	bra.uni 	BB6_28;

BB6_14:
	mov.u32 	%r26, %r108;
	bra.uni 	BB6_35;

BB6_25:
	setp.geu.f32	%p55, %f68, 0f00000000;
	@%p55 bra 	BB6_28;

	mov.f32 	%f467, 0f42480000;
	cvt.rzi.f32.f32	%f317, %f467;
	setp.neu.f32	%p56, %f317, 0f42480000;
	selp.f32	%f482, 0f7FFFFFFF, %f482, %p56;

BB6_28:
	add.f32 	%f319, %f70, 0f42480000;
	mov.b32 	 %r78, %f319;
	setp.lt.s32	%p58, %r78, 2139095040;
	@%p58 bra 	BB6_33;

	setp.gtu.f32	%p59, %f70, 0f7F800000;
	@%p59 bra 	BB6_32;
	bra.uni 	BB6_30;

BB6_32:
	add.f32 	%f482, %f68, 0f42480000;
	bra.uni 	BB6_33;

BB6_30:
	setp.neu.f32	%p60, %f70, 0f7F800000;
	@%p60 bra 	BB6_33;

	selp.f32	%f482, 0fFF800000, 0f7F800000, %p4;

BB6_33:
	mul.wide.s32 	%rd81, %r108, 16;
	add.s64 	%rd80, %rd2, %rd81;
	mul.f32 	%f320, %f482, 0f3F4CCCCD;
	setp.eq.f32	%p61, %f68, 0f3F800000;
	selp.f32	%f321, 0f3F4CCCCD, %f320, %p61;
	add.f32 	%f322, %f66, %f321;
	add.f32 	%f323, %f65, %f321;
	st.local.v2.f32 	[%rd80], {%f323, %f322};
	add.f32 	%f324, %f321, %f67;
	st.local.f32 	[%rd80+8], %f324;

BB6_34:
	add.s32 	%r26, %r108, 1;
	add.f32 	%f325, %f43, %f43;
	mul.f32 	%f326, %f325, %f46;
	add.f32 	%f327, %f44, %f44;
	mul.f32 	%f328, %f327, %f46;
	add.f32 	%f329, %f45, %f45;
	mul.f32 	%f330, %f329, %f46;
	sub.f32 	%f331, %f326, %f40;
	sub.f32 	%f332, %f328, %f41;
	sub.f32 	%f333, %f330, %f42;
	mul.f32 	%f334, %f332, %f332;
	fma.rn.f32 	%f335, %f331, %f331, %f334;
	fma.rn.f32 	%f336, %f333, %f333, %f335;
	rsqrt.approx.f32 	%f337, %f336;
	mul.f32 	%f470, %f331, %f337;
	mul.f32 	%f469, %f332, %f337;
	mul.f32 	%f468, %f333, %f337;
	fma.rn.f32 	%f473, %f470, 0f38D1B717, %f33;
	fma.rn.f32 	%f472, %f469, 0f38D1B717, %f34;
	fma.rn.f32 	%f471, %f468, 0f38D1B717, %f35;

BB6_35:
	add.s32 	%r108, %r108, 1;
	setp.eq.s32	%p62, %r26, %r108;
	setp.lt.u32	%p63, %r108, 5;
	and.pred  	%p64, %p63, %p62;
	@%p64 bra 	BB6_2;

	add.s32 	%r27, %r26, -1;
	setp.lt.s32	%p65, %r27, 1;
	@%p65 bra 	BB6_49;

	and.b32  	%r28, %r27, 3;
	setp.eq.s32	%p66, %r28, 0;
	@%p66 bra 	BB6_38;

	setp.eq.s32	%p67, %r28, 1;
	@%p67 bra 	BB6_40;
	bra.uni 	BB6_41;

BB6_40:
	mov.u32 	%r127, %r27;
	mov.u32 	%r125, %r26;
	bra.uni 	BB6_45;

BB6_38:
	mov.u32 	%r128, %r27;
	mov.u32 	%r127, %r26;
	bra.uni 	BB6_46;

BB6_41:
	setp.eq.s32	%p68, %r28, 2;
	add.s32 	%r125, %r26, -2;
	mul.wide.s32 	%rd65, %r125, 16;
	add.s64 	%rd8, %rd2, %rd65;
	@%p68 bra 	BB6_43;
	bra.uni 	BB6_42;

BB6_43:
	ld.local.v4.f32 	{%f489, %f490, %f491, %f492}, [%rd8+16];
	mov.u32 	%r125, %r27;
	bra.uni 	BB6_44;

BB6_42:
	ld.local.v4.f32 	{%f338, %f339, %f340, %f341}, [%rd8];
	ld.local.v4.f32 	{%f346, %f347, %f348, %f349}, [%rd8+16];
	fma.rn.f32 	%f492, %f349, 0f3F4CCCCD, %f341;
	fma.rn.f32 	%f491, %f348, 0f3F4CCCCD, %f340;
	fma.rn.f32 	%f490, %f347, 0f3F4CCCCD, %f339;
	fma.rn.f32 	%f489, %f346, 0f3F4CCCCD, %f338;
	st.local.v4.f32 	[%rd8], {%f489, %f490, %f491, %f492};
	mov.u32 	%r26, %r27;

BB6_44:
	add.s32 	%r79, %r26, -2;
	mul.wide.s32 	%rd66, %r79, 16;
	add.s64 	%rd67, %rd2, %rd66;
	ld.local.v4.f32 	{%f358, %f359, %f360, %f361}, [%rd67];
	fma.rn.f32 	%f366, %f492, 0f3F4CCCCD, %f361;
	fma.rn.f32 	%f367, %f491, 0f3F4CCCCD, %f360;
	fma.rn.f32 	%f368, %f490, 0f3F4CCCCD, %f359;
	fma.rn.f32 	%f369, %f489, 0f3F4CCCCD, %f358;
	st.local.v4.f32 	[%rd67], {%f369, %f368, %f367, %f366};
	add.s32 	%r127, %r125, -1;

BB6_45:
	add.s32 	%r80, %r125, -2;
	mul.wide.s32 	%rd68, %r80, 16;
	add.s64 	%rd69, %rd2, %rd68;
	ld.local.v4.f32 	{%f370, %f371, %f372, %f373}, [%rd69];
	mul.wide.s32 	%rd70, %r127, 16;
	add.s64 	%rd71, %rd2, %rd70;
	ld.local.v4.f32 	{%f378, %f379, %f380, %f381}, [%rd71];
	fma.rn.f32 	%f386, %f381, 0f3F4CCCCD, %f373;
	fma.rn.f32 	%f387, %f380, 0f3F4CCCCD, %f372;
	fma.rn.f32 	%f388, %f379, 0f3F4CCCCD, %f371;
	fma.rn.f32 	%f389, %f378, 0f3F4CCCCD, %f370;
	st.local.v4.f32 	[%rd69], {%f389, %f388, %f387, %f386};
	add.s32 	%r128, %r127, -1;

BB6_46:
	setp.lt.u32	%p69, %r27, 4;
	@%p69 bra 	BB6_49;

	mul.wide.s32 	%rd72, %r128, 16;
	add.s64 	%rd73, %rd2, %rd72;
	ld.local.v4.f32 	{%f493, %f494, %f495, %f496}, [%rd73];

BB6_48:
	add.s32 	%r81, %r127, -2;
	mul.wide.s32 	%rd74, %r81, 16;
	add.s64 	%rd75, %rd2, %rd74;
	ld.local.v4.f32 	{%f394, %f395, %f396, %f397}, [%rd75];
	fma.rn.f32 	%f402, %f496, 0f3F4CCCCD, %f397;
	fma.rn.f32 	%f403, %f495, 0f3F4CCCCD, %f396;
	fma.rn.f32 	%f404, %f494, 0f3F4CCCCD, %f395;
	fma.rn.f32 	%f405, %f493, 0f3F4CCCCD, %f394;
	st.local.v4.f32 	[%rd75], {%f405, %f404, %f403, %f402};
	mul.wide.s32 	%rd76, %r128, 16;
	add.s64 	%rd77, %rd2, %rd76;
	ld.local.v4.f32 	{%f406, %f407, %f408, %f409}, [%rd77+-32];
	ld.local.v4.f32 	{%f414, %f415, %f416, %f417}, [%rd77+-16];
	fma.rn.f32 	%f422, %f417, 0f3F4CCCCD, %f409;
	fma.rn.f32 	%f423, %f416, 0f3F4CCCCD, %f408;
	fma.rn.f32 	%f424, %f415, 0f3F4CCCCD, %f407;
	fma.rn.f32 	%f425, %f414, 0f3F4CCCCD, %f406;
	st.local.v4.f32 	[%rd77+-32], {%f425, %f424, %f423, %f422};
	ld.local.v4.f32 	{%f426, %f427, %f428, %f429}, [%rd77+-48];
	fma.rn.f32 	%f434, %f422, 0f3F4CCCCD, %f429;
	fma.rn.f32 	%f435, %f423, 0f3F4CCCCD, %f428;
	fma.rn.f32 	%f436, %f424, 0f3F4CCCCD, %f427;
	fma.rn.f32 	%f437, %f425, 0f3F4CCCCD, %f426;
	st.local.v4.f32 	[%rd77+-48], {%f437, %f436, %f435, %f434};
	ld.local.v4.f32 	{%f438, %f439, %f440, %f441}, [%rd77+-64];
	fma.rn.f32 	%f496, %f434, 0f3F4CCCCD, %f441;
	fma.rn.f32 	%f495, %f435, 0f3F4CCCCD, %f440;
	fma.rn.f32 	%f494, %f436, 0f3F4CCCCD, %f439;
	fma.rn.f32 	%f493, %f437, 0f3F4CCCCD, %f438;
	st.local.v4.f32 	[%rd77+-64], {%f493, %f494, %f495, %f496};
	add.s32 	%r40, %r128, -4;
	setp.gt.s32	%p70, %r40, 0;
	add.s32 	%r127, %r128, -3;
	mov.u32 	%r128, %r40;
	@%p70 bra 	BB6_48;

BB6_49:
	ld.param.u64 	%rd85, [_Z6renderPjPP6Objectjjfi_param_0];
	mov.u32 	%r107, %ntid.y;
	mov.u32 	%r106, %ctaid.y;
	mul24.lo.u32 	%r105, %r106, %r107;
	mov.u32 	%r104, %tid.y;
	mov.u32 	%r103, %ntid.x;
	mov.u32 	%r102, %ctaid.x;
	mul24.lo.u32 	%r101, %r102, %r103;
	mov.u32 	%r100, %tid.x;
	add.s32 	%r99, %r100, %r101;
	ld.param.u32 	%r98, [_Z6renderPjPP6Objectjjfi_param_2];
	add.s32 	%r97, %r104, %r105;
	mad.lo.s32 	%r96, %r97, %r98, %r99;
	mul.wide.u32 	%rd84, %r96, 4;
	cvta.to.global.u64 	%rd83, %rd85;
	add.s64 	%rd82, %rd83, %rd84;
	ld.local.v4.f32 	{%f446, %f447, %f448, %f449}, [%rd2];
	cvt.sat.f32.f32	%f454, %f446;
	cvt.sat.f32.f32	%f455, %f447;
	cvt.sat.f32.f32	%f456, %f448;
	cvt.sat.f32.f32	%f457, %f449;
	mul.f32 	%f458, %f457, 0f437F0000;
	cvt.rzi.u32.f32	%r82, %f458;
	shl.b32 	%r83, %r82, 24;
	mul.f32 	%f459, %f456, 0f437F0000;
	cvt.rzi.u32.f32	%r84, %f459;
	shl.b32 	%r85, %r84, 16;
	or.b32  	%r86, %r85, %r83;
	mul.f32 	%f460, %f455, 0f437F0000;
	cvt.rzi.u32.f32	%r87, %f460;
	shl.b32 	%r88, %r87, 8;
	or.b32  	%r89, %r86, %r88;
	mul.f32 	%f461, %f454, 0f437F0000;
	cvt.rzi.u32.f32	%r90, %f461;
	or.b32  	%r91, %r89, %r90;
	ld.global.u32 	%r92, [%rd82];
	add.s32 	%r93, %r91, %r92;
	st.global.u32 	[%rd82], %r93;

BB6_50:
	ret;
}

	// .globl	_Z11dump_vtableI5PlainEvPPvS2_
.visible .entry _Z11dump_vtableI5PlainEvPPvS2_(
	.param .u64 _Z11dump_vtableI5PlainEvPPvS2__param_0,
	.param .u64 _Z11dump_vtableI5PlainEvPPvS2__param_1
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<59>;


	ld.param.u64 	%rd17, [_Z11dump_vtableI5PlainEvPPvS2__param_0];
	ld.param.u64 	%rd18, [_Z11dump_vtableI5PlainEvPPvS2__param_1];
	mov.u64 	%rd58, 0;
	mov.u64 	%rd20, buf5;
	cvta.global.u64 	%rd21, %rd20;
	setp.eq.s64	%p1, %rd21, 0;
	@%p1 bra 	BB7_2;

	mov.f32 	%f1, 0f00000000;
	st.global.v2.f32 	[buf5+8], {%f1, %f1};
	st.global.v4.f32 	[buf5+16], {%f1, %f1, %f1, %f1};
	mov.u32 	%r3, 0;
	st.global.u32 	[buf5+32], %r3;
	mov.u64 	%rd23, _ZTV5Plain;
	add.s64 	%rd24, %rd23, 16;
	cvta.global.u64 	%rd25, %rd24;
	st.global.u64 	[buf5], %rd25;
	mov.u64 	%rd58, %rd20;

BB7_2:
	cvta.to.global.u64 	%rd2, %rd17;
	ld.global.u8 	%rs1, [%rd58];
	cvta.to.global.u64 	%rd26, %rd18;
	st.global.u8 	[%rd26], %rs1;
	ld.global.u8 	%rs2, [%rd58+1];
	st.global.u8 	[%rd26+1], %rs2;
	ld.global.u8 	%rs3, [%rd58+2];
	st.global.u8 	[%rd26+2], %rs3;
	ld.global.u8 	%rs4, [%rd58+3];
	st.global.u8 	[%rd26+3], %rs4;
	ld.global.u8 	%rs5, [%rd58+4];
	st.global.u8 	[%rd26+4], %rs5;
	ld.global.u8 	%rs6, [%rd58+5];
	st.global.u8 	[%rd26+5], %rs6;
	ld.global.u8 	%rs7, [%rd58+6];
	st.global.u8 	[%rd26+6], %rs7;
	ld.global.u8 	%rs8, [%rd58+7];
	st.global.u8 	[%rd26+7], %rs8;
	mov.u32 	%r15, 0;

BB7_3:
	cvt.s64.s32	%rd4, %r15;
	ld.global.u64 	%rd27, [%rd58];
	mul.wide.s32 	%rd28, %r15, 8;
	add.s64 	%rd29, %rd27, %rd28;
	ld.u64 	%rd5, [%rd29];
	setp.eq.s64	%p2, %rd5, 0;
	@%p2 bra 	BB7_14;

	add.s64 	%rd6, %rd2, %rd28;
	st.global.u64 	[%rd6], %rd5;
	add.s32 	%r5, %r15, 1;
	ld.global.u64 	%rd31, [%rd58];
	mul.wide.s32 	%rd32, %r5, 8;
	add.s64 	%rd33, %rd31, %rd32;
	ld.u64 	%rd7, [%rd33];
	setp.eq.s64	%p3, %rd7, 0;
	@%p3 bra 	BB7_14;

	st.global.u64 	[%rd6+8], %rd7;
	add.s32 	%r6, %r15, 2;
	ld.global.u64 	%rd34, [%rd58];
	mul.wide.s32 	%rd35, %r6, 8;
	add.s64 	%rd36, %rd34, %rd35;
	ld.u64 	%rd9, [%rd36];
	setp.eq.s64	%p4, %rd9, 0;
	@%p4 bra 	BB7_14;

	st.global.u64 	[%rd6+16], %rd9;
	add.s32 	%r7, %r15, 3;
	ld.global.u64 	%rd37, [%rd58];
	mul.wide.s32 	%rd38, %r7, 8;
	add.s64 	%rd39, %rd37, %rd38;
	ld.u64 	%rd10, [%rd39];
	setp.eq.s64	%p5, %rd10, 0;
	@%p5 bra 	BB7_14;

	st.global.u64 	[%rd6+24], %rd10;
	add.s32 	%r8, %r15, 4;
	ld.global.u64 	%rd40, [%rd58];
	mul.wide.s32 	%rd41, %r8, 8;
	add.s64 	%rd42, %rd40, %rd41;
	ld.u64 	%rd11, [%rd42];
	setp.eq.s64	%p6, %rd11, 0;
	@%p6 bra 	BB7_14;

	st.global.u64 	[%rd6+32], %rd11;
	add.s32 	%r9, %r15, 5;
	ld.global.u64 	%rd43, [%rd58];
	mul.wide.s32 	%rd44, %r9, 8;
	add.s64 	%rd45, %rd43, %rd44;
	ld.u64 	%rd12, [%rd45];
	setp.eq.s64	%p7, %rd12, 0;
	@%p7 bra 	BB7_14;

	st.global.u64 	[%rd6+40], %rd12;
	add.s32 	%r10, %r15, 6;
	ld.global.u64 	%rd46, [%rd58];
	mul.wide.s32 	%rd47, %r10, 8;
	add.s64 	%rd48, %rd46, %rd47;
	ld.u64 	%rd13, [%rd48];
	setp.eq.s64	%p8, %rd13, 0;
	@%p8 bra 	BB7_14;

	st.global.u64 	[%rd6+48], %rd13;
	add.s32 	%r11, %r15, 7;
	ld.global.u64 	%rd49, [%rd58];
	mul.wide.s32 	%rd50, %r11, 8;
	add.s64 	%rd51, %rd49, %rd50;
	ld.u64 	%rd14, [%rd51];
	setp.eq.s64	%p9, %rd14, 0;
	@%p9 bra 	BB7_14;

	st.global.u64 	[%rd6+56], %rd14;
	add.s32 	%r12, %r15, 8;
	ld.global.u64 	%rd52, [%rd58];
	mul.wide.s32 	%rd53, %r12, 8;
	add.s64 	%rd54, %rd52, %rd53;
	ld.u64 	%rd15, [%rd54];
	setp.eq.s64	%p10, %rd15, 0;
	@%p10 bra 	BB7_14;

	st.global.u64 	[%rd6+64], %rd15;
	add.s32 	%r13, %r15, 9;
	ld.global.u64 	%rd55, [%rd58];
	mul.wide.s32 	%rd56, %r13, 8;
	add.s64 	%rd57, %rd55, %rd56;
	ld.u64 	%rd16, [%rd57];
	setp.eq.s64	%p11, %rd16, 0;
	@%p11 bra 	BB7_14;

	cvt.u32.u64	%r14, %rd4;
	st.global.u64 	[%rd6+72], %rd16;
	add.s32 	%r15, %r14, 10;
	setp.lt.s32	%p12, %r15, 30;
	@%p12 bra 	BB7_3;

BB7_14:
	ret;
}

	// .globl	_Z11dump_vtableI6SphereEvPPvS2_
.visible .entry _Z11dump_vtableI6SphereEvPPvS2_(
	.param .u64 _Z11dump_vtableI6SphereEvPPvS2__param_0,
	.param .u64 _Z11dump_vtableI6SphereEvPPvS2__param_1
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<59>;


	ld.param.u64 	%rd17, [_Z11dump_vtableI6SphereEvPPvS2__param_0];
	ld.param.u64 	%rd18, [_Z11dump_vtableI6SphereEvPPvS2__param_1];
	mov.u64 	%rd58, 0;
	mov.u64 	%rd20, buf5;
	cvta.global.u64 	%rd21, %rd20;
	setp.eq.s64	%p1, %rd21, 0;
	@%p1 bra 	BB8_2;

	mov.f32 	%f1, 0f00000000;
	st.global.v2.f32 	[buf5+8], {%f1, %f1};
	st.global.v4.f32 	[buf5+16], {%f1, %f1, %f1, %f1};
	mov.u32 	%r3, 0;
	st.global.u32 	[buf5+32], %r3;
	mov.u64 	%rd23, _ZTV6Sphere;
	add.s64 	%rd24, %rd23, 16;
	cvta.global.u64 	%rd25, %rd24;
	st.global.u64 	[buf5], %rd25;
	mov.u64 	%rd58, %rd20;

BB8_2:
	cvta.to.global.u64 	%rd2, %rd17;
	ld.global.u8 	%rs1, [%rd58];
	cvta.to.global.u64 	%rd26, %rd18;
	st.global.u8 	[%rd26], %rs1;
	ld.global.u8 	%rs2, [%rd58+1];
	st.global.u8 	[%rd26+1], %rs2;
	ld.global.u8 	%rs3, [%rd58+2];
	st.global.u8 	[%rd26+2], %rs3;
	ld.global.u8 	%rs4, [%rd58+3];
	st.global.u8 	[%rd26+3], %rs4;
	ld.global.u8 	%rs5, [%rd58+4];
	st.global.u8 	[%rd26+4], %rs5;
	ld.global.u8 	%rs6, [%rd58+5];
	st.global.u8 	[%rd26+5], %rs6;
	ld.global.u8 	%rs7, [%rd58+6];
	st.global.u8 	[%rd26+6], %rs7;
	ld.global.u8 	%rs8, [%rd58+7];
	st.global.u8 	[%rd26+7], %rs8;
	mov.u32 	%r15, 0;

BB8_3:
	cvt.s64.s32	%rd4, %r15;
	ld.global.u64 	%rd27, [%rd58];
	mul.wide.s32 	%rd28, %r15, 8;
	add.s64 	%rd29, %rd27, %rd28;
	ld.u64 	%rd5, [%rd29];
	setp.eq.s64	%p2, %rd5, 0;
	@%p2 bra 	BB8_14;

	add.s64 	%rd6, %rd2, %rd28;
	st.global.u64 	[%rd6], %rd5;
	add.s32 	%r5, %r15, 1;
	ld.global.u64 	%rd31, [%rd58];
	mul.wide.s32 	%rd32, %r5, 8;
	add.s64 	%rd33, %rd31, %rd32;
	ld.u64 	%rd7, [%rd33];
	setp.eq.s64	%p3, %rd7, 0;
	@%p3 bra 	BB8_14;

	st.global.u64 	[%rd6+8], %rd7;
	add.s32 	%r6, %r15, 2;
	ld.global.u64 	%rd34, [%rd58];
	mul.wide.s32 	%rd35, %r6, 8;
	add.s64 	%rd36, %rd34, %rd35;
	ld.u64 	%rd9, [%rd36];
	setp.eq.s64	%p4, %rd9, 0;
	@%p4 bra 	BB8_14;

	st.global.u64 	[%rd6+16], %rd9;
	add.s32 	%r7, %r15, 3;
	ld.global.u64 	%rd37, [%rd58];
	mul.wide.s32 	%rd38, %r7, 8;
	add.s64 	%rd39, %rd37, %rd38;
	ld.u64 	%rd10, [%rd39];
	setp.eq.s64	%p5, %rd10, 0;
	@%p5 bra 	BB8_14;

	st.global.u64 	[%rd6+24], %rd10;
	add.s32 	%r8, %r15, 4;
	ld.global.u64 	%rd40, [%rd58];
	mul.wide.s32 	%rd41, %r8, 8;
	add.s64 	%rd42, %rd40, %rd41;
	ld.u64 	%rd11, [%rd42];
	setp.eq.s64	%p6, %rd11, 0;
	@%p6 bra 	BB8_14;

	st.global.u64 	[%rd6+32], %rd11;
	add.s32 	%r9, %r15, 5;
	ld.global.u64 	%rd43, [%rd58];
	mul.wide.s32 	%rd44, %r9, 8;
	add.s64 	%rd45, %rd43, %rd44;
	ld.u64 	%rd12, [%rd45];
	setp.eq.s64	%p7, %rd12, 0;
	@%p7 bra 	BB8_14;

	st.global.u64 	[%rd6+40], %rd12;
	add.s32 	%r10, %r15, 6;
	ld.global.u64 	%rd46, [%rd58];
	mul.wide.s32 	%rd47, %r10, 8;
	add.s64 	%rd48, %rd46, %rd47;
	ld.u64 	%rd13, [%rd48];
	setp.eq.s64	%p8, %rd13, 0;
	@%p8 bra 	BB8_14;

	st.global.u64 	[%rd6+48], %rd13;
	add.s32 	%r11, %r15, 7;
	ld.global.u64 	%rd49, [%rd58];
	mul.wide.s32 	%rd50, %r11, 8;
	add.s64 	%rd51, %rd49, %rd50;
	ld.u64 	%rd14, [%rd51];
	setp.eq.s64	%p9, %rd14, 0;
	@%p9 bra 	BB8_14;

	st.global.u64 	[%rd6+56], %rd14;
	add.s32 	%r12, %r15, 8;
	ld.global.u64 	%rd52, [%rd58];
	mul.wide.s32 	%rd53, %r12, 8;
	add.s64 	%rd54, %rd52, %rd53;
	ld.u64 	%rd15, [%rd54];
	setp.eq.s64	%p10, %rd15, 0;
	@%p10 bra 	BB8_14;

	st.global.u64 	[%rd6+64], %rd15;
	add.s32 	%r13, %r15, 9;
	ld.global.u64 	%rd55, [%rd58];
	mul.wide.s32 	%rd56, %r13, 8;
	add.s64 	%rd57, %rd55, %rd56;
	ld.u64 	%rd16, [%rd57];
	setp.eq.s64	%p11, %rd16, 0;
	@%p11 bra 	BB8_14;

	cvt.u32.u64	%r14, %rd4;
	st.global.u64 	[%rd6+72], %rd16;
	add.s32 	%r15, %r14, 10;
	setp.lt.s32	%p12, %r15, 30;
	@%p12 bra 	BB8_3;

BB8_14:
	ret;
}


